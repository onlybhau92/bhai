# -*- coding: utf-8 -*-
"""DLassign2offlinedataset.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Vaxxu5vx4OnCZADYX60uJ15HEwinD4mn
"""

import pandas as pd
import numpy as np
from tensorflow.keras.preprocessing.text import Tokenizer
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

# 1. Load dataset
df = pd.read_csv('IMDB Dataset.csv')

# 2. Convert labels: positive -> 1, negative -> 0
df['sentiment'] = df['sentiment'].map({'positive': 1, 'negative': 0})

# 3. Extract text and labels
texts = df['review'].astype(str).tolist()
labels = df['sentiment'].astype(int).tolist()

# 4. Tokenize text
max_words = 10000
tokenizer = Tokenizer(num_words=max_words)
tokenizer.fit_on_texts(texts)

# 5. Convert texts to binary matrix (bag of words model)
x_data = tokenizer.texts_to_matrix(texts, mode='binary')
y_data = np.array(labels).astype('float32')

# 6. Split into train and test sets
x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.3, random_state=42)

# 7. Build model
model = Sequential()
model.add(Dense(16, activation='relu', input_shape=(max_words,)))
model.add(Dense(16, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

# 8. Compile model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# 9. Train model
history = model.fit(x_train, y_train, epochs=10, batch_size=512, validation_split=0.2, verbose=1)

# 10. Evaluate
test_loss, test_acc = model.evaluate(x_test, y_test)
print(f"\nTest Accuracy: {test_acc:.4f}, Test Loss: {test_loss:.4f}")

# 11. Predict on test set
predictions = model.predict(x_test)

# 12. Show sample predictions
for i in range(10):
    predicted_label = 1 if predictions[i] >= 0.5 else 0
    print(f"Review {i+1}: Predicted = {predicted_label}, Actual = {int(y_test[i])}")