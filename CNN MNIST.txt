
import pandas as pd
import numpy as np

# Load data
train_df = pd.read_csv('fashion-mnist_train.csv')
test_df = pd.read_csv('fashion-mnist_test.csv')

# Split into features and labels
train_x = train_df.iloc[:, 1:].values / 255.0
train_y = train_df.iloc[:, 0].values

test_x = test_df.iloc[:, 1:].values / 255.0
test_y = test_df.iloc[:, 0].values

# Reshape for CNN input
train_x = train_x.reshape(-1, 28, 28, 1).astype(np.float32)
test_x = test_x.reshape(-1, 28, 28, 1).astype(np.float32)






from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense

model = Sequential()
model.add(Conv2D(64, (3,3), activation='relu', input_shape=(28,28,1)))
model.add(MaxPooling2D((2,2)))
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dense(10, activation='softmax'))  # 10 classes




model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Train the model
model.fit(train_x, train_y, epochs=5, validation_split=0.2)



# Evaluate
loss, accuracy = model.evaluate(test_x, test_y)
print(f"Test Accuracy: {accuracy*100:.2f}%")

# Predict a sample
labels = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
          'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

import matplotlib.pyplot as plt
pred = model.predict(test_x[:1])
predicted_label = labels[np.argmax(pred)]

plt.imshow(test_x[0].reshape(28, 28), cmap='gray')
plt.title(f"Predicted: {predicted_label}")
plt.axis('off')
plt.show()




#ye cell run mat karna
target_label_index = labels.index('T-shirt/top')  # Change 'sneaker' to any other category

# Loop to find the first test image of that category
for i in range(len(test_y)):
    if test_y[i] == target_label_index:
        test_image = test_x[i].astype('float32') / 255.0
        test_image = test_image.reshape(1, 28, 28, 1)

        prediction = model.predict(test_image)
        predicted_label = labels[np.argmax(prediction)]

        print(f"Actual Label: {labels[test_y[i]]}")
        print(f"Predicted Label: {predicted_label}")

        plt.imshow(test_x[i], cmap='gray')
        plt.title(f"Predicted: {predicted_label}")
        plt.axis('off')
        plt.show()
        break  # Stop after showing the first match

























#Netwala
import numpy as np
from tensorflow.keras.datasets import fashion_mnist







(train_x, train_y), (test_x, test_y) = fashion_mnist.load_data()









from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten, MaxPooling2D, Conv2D









model = Sequential()










model.add(Conv2D(filters=64,kernel_size=(3,3),activation='relu',input_shape=(28, 28, 1)))

# Adding maxpooling layer to get max value within a matrix
model.add(MaxPooling2D(pool_size=(2,2)))

model.add(Flatten())
model.add(Dense(128, activation = "relu"))
model.add(Dense(10, activation = "softmax"))














model.summary()















model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])















loss, acc = model.evaluate(test_x, test_y)















labels = ['t_shirt', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker',   'bag', 'ankle_boots']















predictions = model.predict(test_x[:1])











import numpy as np













label = labels[np.argmax(predictions)]















import matplotlib.pyplot as plt
print(label)
plt.imshow(test_x[:1][0])
plt.show






target_label_index = labels.index('ankle_boots')  # Change 'sneaker' to any other category

# Loop to find the first test image of that category
for i in range(len(test_y)):
    if test_y[i] == target_label_index:
        test_image = test_x[i].astype('float32') / 255.0
        test_image = test_image.reshape(1, 28, 28, 1)

        prediction = model.predict(test_image)
        predicted_label = labels[np.argmax(prediction)]

        print(f"Actual Label: {labels[test_y[i]]}")
        print(f"Predicted Label: {predicted_label}")

        plt.imshow(test_x[i], cmap='gray')
        plt.title(f"Predicted: {predicted_label}")
        plt.axis('off')
        plt.show()
        break  # Stop after showing the first match

--------------------------------------------------------------------------------------------------------------------------------


Theory for the Practical:
This code demonstrates how to build and evaluate a Convolutional Neural Network (CNN) using the Fashion MNIST dataset, which is a popular dataset for image classification tasks. The goal is to classify images of clothing items into one of ten categories. Let's break down the key steps involved in this process:

1. Loading the Fashion MNIST Dataset
python
Copy
Edit
from tensorflow.keras.datasets import fashion_mnist

(train_x, train_y), (test_x, test_y) = fashion_mnist.load_data()
Fashion MNIST Dataset: This dataset contains 60,000 grayscale images for training and 10,000 grayscale images for testing. Each image is 28x28 pixels, and the task is to classify each image into one of 10 categories of clothing (e.g., t-shirt, trouser, dress, etc.).

train_x: The image data for training, consisting of 60,000 images (28x28 pixels).

train_y: The labels corresponding to the training images, indicating which category each image belongs to.

test_x: The image data for testing, consisting of 10,000 images.

test_y: The labels for the test images.

2. Model Architecture: Convolutional Neural Network (CNN)
python
Copy
Edit
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten, MaxPooling2D, Conv2D

model = Sequential()
Sequential Model: A linear stack of layers where each layer has exactly one input and one output.

CNN Layers: Convolutional neural networks are particularly well-suited for image classification tasks because they can detect spatial hierarchies in the data (e.g., edges, textures, and patterns).

Adding Layers:
Conv2D Layer:

python
Copy
Edit
model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu', input_shape=(28, 28, 1)))
Conv2D: This is a convolutional layer that applies 64 convolutional filters of size 3x3 to the input image.

Activation Function: ReLU (Rectified Linear Unit) is used to introduce non-linearity, allowing the model to learn complex patterns.

Input Shape: The input image is 28x28 pixels with 1 color channel (grayscale).

MaxPooling2D Layer:

python
Copy
Edit
model.add(MaxPooling2D(pool_size=(2,2)))
MaxPooling2D: A max-pooling layer that reduces the spatial dimensions (height and width) of the image by taking the maximum value from a 2x2 region, effectively downsampling the image and retaining important features.

Flatten Layer:

python
Copy
Edit
model.add(Flatten())
Flatten: Converts the 2D matrix of the pooled image into a 1D vector so that it can be passed to the fully connected (dense) layers.

Dense Layers:

python
Copy
Edit
model.add(Dense(128, activation="relu"))
model.add(Dense(10, activation="softmax"))
Dense(128): A fully connected layer with 128 neurons. The ReLU activation function is used again.

Dense(10): The output layer has 10 neurons, each corresponding to one of the 10 classes. The softmax activation function is used because it's ideal for multi-class classification problems, as it converts the output into probabilities that sum to 1.

3. Model Summary
python
Copy
Edit
model.summary()
The summary() method shows a summary of the model architecture, including the number of parameters in each layer, the total number of parameters in the model, and the output shape at each stage of the network.

4. Compiling the Model
python
Copy
Edit
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
Optimizer: Adam is a popular optimization algorithm that adjusts the learning rate during training.

Loss Function: Sparse Categorical Cross-Entropy is used for multi-class classification problems when the labels are provided as integers (not one-hot encoded).

Metrics: Accuracy is chosen as the metric to evaluate the performance of the model.

5. Evaluating the Model
python
Copy
Edit
loss, acc = model.evaluate(test_x, test_y)
The model is evaluated on the test dataset (test_x, test_y).

Loss: The loss value (sparse categorical cross-entropy).

Accuracy: The proportion of correctly classified samples.

6. Making Predictions
python
Copy
Edit
predictions = model.predict(test_x[:1])
Predictions: The model makes predictions on the test dataset. The model outputs a probability distribution over the 10 classes for each image. The class with the highest probability is the predicted label.

test_x[:1] selects the first image in the test set for prediction.

7. Mapping Predictions to Class Labels
python
Copy
Edit
labels = ['t_shirt', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle_boots']

label = labels[np.argmax(predictions)]
Labels: A list of the 10 clothing categories corresponding to the Fashion MNIST dataset.

np.argmax(predictions): The argmax function finds the index of the class with the highest predicted probability, which corresponds to the predicted label. This is then mapped to the human-readable class name using the labels list.

8. Visualizing the Prediction
python
Copy
Edit
import matplotlib.pyplot as plt
print(label)
plt.imshow(test_x[:1][0])
plt.show()
Matplotlib is used to visualize the image corresponding to the predicted label.

The imshow() function is used to display the image, and plt.show() renders the image on the screen.

The predicted label is printed before displaying the image.

Key Takeaways:
Convolutional Layers: The CNN uses convolutional layers to extract features from images, followed by pooling layers to reduce the image size and focus on important features.

Dense Layers: After feature extraction, the model flattens the features into a 1D vector and uses fully connected layers to classify the image into one of the 10 categories.

Model Evaluation: The model's performance is evaluated on the test set using accuracy, and predictions are made on individual test samples.

Visualization: The image corresponding to the predicted label is displayed, allowing you to visually verify the modelâ€™s prediction.
